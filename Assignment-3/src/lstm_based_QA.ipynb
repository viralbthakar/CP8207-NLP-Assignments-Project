{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Attention\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USAGE: GOAL two methods are best so run code under the *Goal 2* headers. Further cleaning coming soon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task definition: \n",
    "FIRST GOAL: Create a LSTM model to take context, and question, and generate an answer\n",
    "INPUT: CQ together like \"[CLS]CONTEXT[SEP]QUESTION[STOP]\" in a list of strings\n",
    "OUTPUT: START_POSITION, END_POSITION] with respect to the context\n",
    "1. Load SQuAD dataset\n",
    "2. Remove puntutation from CQ input\n",
    "3. Create input, and output lists\n",
    "4. Tokenize data\n",
    "5. Pad data\n",
    "6. Create a loss function to get the correct start and end\n",
    "\n",
    "\n",
    "SECOND GOAL: Create a biLSTM model to take context, and question, and generate an answer\n",
    "INPUT: Two inputs, each into their own biLSTM, one: \"CONTEXT\", two: \"QUESTION\"\n",
    "OUTPUT: [[START_POSITION], [END_POSITION]] one-hot-encoded with respect to the context\n",
    "1. Load SQuAD dataset\n",
    "2. Clean Context, and Question input\n",
    "3. Create input, and output lists\n",
    "4. Tokenize data\n",
    "5. Pad data\n",
    "6. Create one-hot-encoding of ANSWERS\n",
    "7. Define Model\n",
    "6. Create a loss function to get the correct start and end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_json(\"../train-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_POC = raw_data[\"data\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Goal\n",
    "Extract the questions and context, as well as answer locations in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CQA_extraction(data):\n",
    "    context_questions = []\n",
    "    answers = []\n",
    "    for topic in data:\n",
    "        for id, cq in enumerate(topic[\"paragraphs\"]):\n",
    "            for x in cq[\"qas\"]:\n",
    "                if x[\"is_impossible\"]==True:\n",
    "                    continue\n",
    "                question_text = x['question']\n",
    "                context_text = cq['context']\n",
    "\n",
    "                context_questions.append(f\"[CLS] {context_text} [SEP] {question_text} [END]\")\n",
    "                \n",
    "                answer_text = x[\"answers\"][0][\"text\"]\n",
    "                answer_start = x[\"answers\"][0][\"answer_start\"]\n",
    "                \n",
    "                answers.append({\"text\":answer_text, \"start\":answer_start, \"end\":answer_start+len(answer_text), \"context\":context_text})#[f\"{x['question']}\"] = \n",
    "    return context_questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_questions, answers = CQA_extraction(testing_POC.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Goal\n",
    "Let's also try to create something that takes two inputs: Context, Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CQA_extraction_twoInputs(data):\n",
    "    context = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for topic in data:\n",
    "        for id, cq in enumerate(topic[\"paragraphs\"]):\n",
    "            for x in cq[\"qas\"]:\n",
    "                if x[\"is_impossible\"]==True:\n",
    "                    continue\n",
    "                question_text = x['question']\n",
    "                context_text = cq['context']\n",
    "\n",
    "                context.append(context_text)\n",
    "\n",
    "                questions.append(question_text)\n",
    "                \n",
    "                answer_text = x[\"answers\"][0][\"text\"]\n",
    "                answer_start = x[\"answers\"][0][\"answer_start\"]\n",
    "                \n",
    "                answers.append({\"text\":answer_text, \"start\":answer_start, \"end\":answer_start+len(answer_text), \"context\":context_text})#[f\"{x['question']}\"] = \n",
    "    return context, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, questions, answers = CQA_extraction_twoInputs(testing_POC.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Questions, and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80133/1433623157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_context_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext_questions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'context_questions' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_context_questions = [clean_text(x) for x in context_questions]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_context = [clean_text(x) for x in context]\n",
    "cleaned_questions = [clean_text(x) for x in questions]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also find the max length of the context!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = max([len(answer[\"context\"]) for answer in answers])\n",
    "context_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_context_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80133/2462188503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fit tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_context_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Define sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_context_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Find max length of sequences for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_context_questions' is not defined"
     ]
    }
   ],
   "source": [
    "#Fit tokenizer\n",
    "tokenizer.fit_on_texts(cleaned_context_questions)\n",
    "#Define sequences\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_context_questions)\n",
    "#Find max length of sequences for padding\n",
    "max_length = max([len(x) for x in sequences])\n",
    "#Pad sequences based on mac length\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Tokenizer\n",
    "tokenizer.fit_on_texts(cleaned_questions+cleaned_context)\n",
    "#Create tokenized sequences of the context, and questions\n",
    "sequences_question = tokenizer.texts_to_sequences(cleaned_questions)\n",
    "sequences_context = tokenizer.texts_to_sequences(cleaned_context)\n",
    "#Find max sequence length of questions and context, together, and seperately\n",
    "#Max's are for padding\n",
    "max_length = max([len(x) for x in sequences_context+sequences_question])\n",
    "max_length_questions = max([len(x) for x in sequences_question])\n",
    "max_length_context = max([len(x) for x in sequences_context])\n",
    "#Pad sequences!\n",
    "padded_sequences_context = pad_sequences(sequences_context, maxlen=max_length_context, padding='post')\n",
    "padded_sequences_questions = pad_sequences(sequences_question, maxlen=max_length_questions, padding='post')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80133/3010638569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Add padded sequences to X set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpadded_sequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'padded_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "#Add padded sequences to X set\n",
    "X = []\n",
    "for x in padded_sequences:\n",
    "    X.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2d array of starts and ends of answers\n",
    "y = [[answer[\"start\"], answer[\"end\"]] for answer in answers]\n",
    "#Normalize data\n",
    "y = [[arr[0]/context_length, arr[1]/context_length] for arr in y]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add padded sequences to X set\n",
    "X = []\n",
    "for id, x in enumerate(padded_sequences_questions):\n",
    "    X.append([padded_sequences_context[id], x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a vector of length conttext\n",
    "y_startPOS = [np.zeros(context_length) for answer in answers]\n",
    "y_endPOS = [np.zeros(context_length) for answer in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_startPOS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the start and end of each answer\n",
    "start_ends = [[answer[\"start\"], answer[\"end\"]] for answer in answers]\n",
    "#Map the start and end of each question to its position in\n",
    "#it's respective vector of length CONTEXT_LENGTH\n",
    "for id, vector in enumerate(y_startPOS):\n",
    "    vector[start_ends[id][0]]=1\n",
    "for id, vector in enumerate(y_endPOS):\n",
    "    vector[start_ends[id][0]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for id, vector in enumerate(y_startPOS):\n",
    "    output_data.append([vector, y_endPOS[id]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Goal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Goal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, output_data, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5729, 3076)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.array([np.array(y_train)[:,0], np.array(y_train)[:,0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Goal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Goal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(context_sequence_length, question_sequence_length, vocab_length):\n",
    "    input_1 = tf.keras.layers.Input(shape=(context_sequence_length,))  # shape of input CONTEXT\n",
    "    input_2 = tf.keras.layers.Input(shape=(question_sequence_length,))  # shape of input QUESTION\n",
    "    #INPUT 1\n",
    "    #Embedding\n",
    "    embedding_1 = Embedding(input_dim=vocab_length, output_dim=4)(input_1)\n",
    "    #LSTM\n",
    "    lstm_1 = LSTM(units=10)(embedding_1)\n",
    "    #INPUT 2\n",
    "    #Embedding\n",
    "    embedding_2 = Embedding(input_dim=vocab_length, output_dim=4)(input_2)\n",
    "    #LSTM\n",
    "    lstm_2 = LSTM(units=10)(embedding_2)\n",
    "    #concat the layers\n",
    "    concatenated = tf.keras.layers.concatenate([lstm_1, lstm_2])\n",
    "    #Dense layer \n",
    "    output_start = Dense(units=3076, activation='softmax')(concatenated)\n",
    "    output_end = Dense(units=3076, activation='softmax')(concatenated)\n",
    "    #Define Model\n",
    "    goal2model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=[output_start, output_end])\n",
    "\n",
    "    #Copile Model\n",
    "    goal2model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return goal2model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "model = create_model(max_length_context, max_length_questions, len(tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5729, 3076)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape([np.array(y_train)[:,0], np.array(y_train)[:,1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "180/180 [==============================] - 31s 155ms/step - loss: 14.7207 - dense_2_loss: 7.3581 - dense_3_loss: 7.3626 - dense_2_accuracy: 0.0232 - dense_3_accuracy: 0.0183\n",
      "Epoch 2/3\n",
      "180/180 [==============================] - 27s 150ms/step - loss: 13.1832 - dense_2_loss: 6.5909 - dense_3_loss: 6.5923 - dense_2_accuracy: 0.0248 - dense_3_accuracy: 0.0248\n",
      "Epoch 3/3\n",
      "180/180 [==============================] - 27s 153ms/step - loss: 13.0783 - dense_2_loss: 6.5389 - dense_3_loss: 6.5394 - dense_2_accuracy: 0.0248 - dense_3_accuracy: 0.0248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc2b7d8730>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([np.array([X[0] for X in X_train]), np.array([X[1] for X in X_train])], \n",
    "          [np.array(y_train)[:,0], np.array(y_train)[:,1]],epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 2s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "l = model.predict([np.array([X[0] for X in X_test]), np.array([X[1] for X in X_test])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_91978/4221198456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "np.argmax(l[3][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function should take into account the start and end of the answer wrt the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_loss(y_true, y_pred):\n",
    "    euclidean_loss = tf.keras.losses.MeanSquaredError()\n",
    "    loss = tf.norm(y_pred - y_true, ord='euclidean')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0][0])) #CONTEXT\n",
    "print(len(X_train[0][1])) #QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_43 (Embedding)    (None, 525, 30)           527940    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 20)               3280      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531,241\n",
      "Trainable params: 531,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len\n",
    "    model = Sequential()\n",
    "    # ----------Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 30, input_length=input_len))\n",
    "    # ----------Add Hidden Layer 1 - LSTM Layer\n",
    "    # model.add(LSTM(64))\n",
    "    lstm_layer = tf.keras.layers.LSTM(units=10)\n",
    "    bilstm_layer = tf.keras.layers.Bidirectional(lstm_layer)\n",
    "    model.add(bilstm_layer)\n",
    "    # ----------Add Output Layer\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.MSE, optimizer='adam')\n",
    "    return model\n",
    "model = create_model(max_length, len(tokenizer.word_index) + 1)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 7639) vs (None, 3076)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80133/3351351210.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 7639) vs (None, 3076)).\n"
     ]
    }
   ],
   "source": [
    "model.fit([np.array([X[0] for X in X_train]), np.array([X[1] for X in X_train])], np.array(y_train)[:,0],epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3076"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(y_train)[:,0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/60 [====>.........................] - ETA: 1s"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_6/embedding_63/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/monty/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/monty/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_22163/4230257143.py\", line 1, in <module>\n      l = model.predict([np.array([X[0] for X in X_test]), np.array([X[1] for X in X_test])])\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_6/embedding_63/embedding_lookup'\nindices[7,91] = 17595 is not in [0, 17595)\n\t [[{{node model_6/embedding_63/embedding_lookup}}]] [Op:__inference_predict_function_187950]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22163/4230257143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_6/embedding_63/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/monty/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/monty/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/monty/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/monty/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_22163/4230257143.py\", line 1, in <module>\n      l = model.predict([np.array([X[0] for X in X_test]), np.array([X[1] for X in X_test])])\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/monty/.local/lib/python3.8/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_6/embedding_63/embedding_lookup'\nindices[7,91] = 17595 is not in [0, 17595)\n\t [[{{node model_6/embedding_63/embedding_lookup}}]] [Op:__inference_predict_function_187950]"
     ]
    }
   ],
   "source": [
    "l = model.predict([np.array([X[0] for X in X_test]), np.array([X[1] for X in X_test])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
